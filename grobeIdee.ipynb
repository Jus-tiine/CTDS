{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16573cd9-54b2-4c6a-bdaa-2b866544e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "\n",
    "class NewsRecommender:\n",
    "    def __init__(self, model_name='multi-qa-MiniLM-L6-cos-v1', batch_size=32):\n",
    "        \"\"\"\n",
    "        Initialize the news recommender system.\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.batch_size = batch_size\n",
    "        self.embeddings = None\n",
    "        self.news_df = None\n",
    "        self.index = None\n",
    "        \n",
    "    def _combine_text(self, row):\n",
    "        \"\"\"Combine title and abstract\"\"\"\n",
    "        # Title is typically more important for recommendation\n",
    "        return f\"{row['title']} {row['title']} {row['abstract']}\"\n",
    "    \n",
    "    def fit(self, news_df):\n",
    "        \"\"\"\n",
    "        Process the news articles and build the recommendation index\n",
    "        \n",
    "        Parameters:\n",
    "        news_df (pd.DataFrame): DataFrame containing 'title' and 'abstract'\n",
    "        \"\"\"\n",
    "        self.news_df = news_df.copy()\n",
    "        \n",
    "        # Prepare texts\n",
    "        texts = []\n",
    "        for _, row in self.news_df.iterrows():\n",
    "            texts.append(self._combine_text(row))\n",
    "        \n",
    "        # Generate embeddings in batches\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(texts), self.batch_size), desc=\"Generating embeddings\"):\n",
    "            batch = texts[i:i + self.batch_size]\n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = self.model.encode(batch)\n",
    "                embeddings.append(batch_embeddings)\n",
    "        \n",
    "        self.embeddings = np.vstack(embeddings)\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity\n",
    "        self.embeddings = normalize(self.embeddings)\n",
    "        \n",
    "        # Build FAISS index for efficient similarity search\n",
    "        self.index = faiss.IndexFlatIP(self.embeddings.shape[1])\n",
    "        self.index.add(self.embeddings.astype('float32'))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_recommendations(self, article_id, n_recommendations=5, exclude_same_category=False):\n",
    "        \"\"\"\n",
    "        Get article recommendations based on a source article.\n",
    "        \n",
    "        Parameters:\n",
    "        article_id: ID of the source article\n",
    "        n_recommendations: Number of recommendations to return\n",
    "        exclude_same_category: Whether to exclude articles from the same category\n",
    "        \n",
    "        Returns:\n",
    "        pd.DataFrame: Recommended articles with similarity scores\n",
    "        \"\"\"\n",
    "        # Get article index\n",
    "        article_idx = self.news_df[self.news_df['news_id'] == article_id].index[0]\n",
    "        query_vector = self.embeddings[article_idx].reshape(1, -1)\n",
    "        \n",
    "        # Get more recommendations than needed in case we filter some out\n",
    "        k = n_recommendations\n",
    "        if exclude_same_category:\n",
    "            k = min(n_recommendations * 3, len(self.news_df))\n",
    "            \n",
    "        # Find similar articles\n",
    "        scores, indices = self.index.search(query_vector.astype('float32'), k)\n",
    "        \n",
    "        # Create recommendations dataframe\n",
    "        recommendations = self.news_df.iloc[indices[0]].copy()\n",
    "        recommendations['similarity_score'] = scores[0]\n",
    "        \n",
    "        # Filter out the source article\n",
    "        recommendations = recommendations[recommendations['news_id'] != article_id]\n",
    "        \n",
    "        if exclude_same_category:\n",
    "            source_category = self.news_df.loc[article_idx, 'category']\n",
    "            recommendations = recommendations[recommendations['category'] != source_category]\n",
    "            recommendations = recommendations.head(n_recommendations)\n",
    "        \n",
    "        return recommendations.reset_index(drop=True)\n",
    "    \n",
    "    def get_recommendations_from_history(self, article_ids, n_recommendations=5):\n",
    "        \"\"\"\n",
    "        Get recommendations based on a user's reading history.\n",
    "        \n",
    "        Parameters:\n",
    "        article_ids: List of article IDs from user's history\n",
    "        n_recommendations: Number of recommendations to return\n",
    "        \n",
    "        Returns:\n",
    "        pd.DataFrame: Recommended articles with similarity scores\n",
    "        \"\"\"\n",
    "        # Get indices for history articles\n",
    "        history_indices = [self.news_df[self.news_df['news_id'] == id_].index[0] \n",
    "                         for id_ in article_ids]\n",
    "        \n",
    "        # Average the embeddings of history articles\n",
    "        query_vector = self.embeddings[history_indices].mean(axis=0).reshape(1, -1)\n",
    "        query_vector = normalize(query_vector)\n",
    "        \n",
    "        # Find similar articles\n",
    "        scores, indices = self.index.search(query_vector.astype('float32'), \n",
    "                                          n_recommendations + len(article_ids))\n",
    "        \n",
    "        # Create recommendations dataframe\n",
    "        recommendations = self.news_df.iloc[indices[0]].copy()\n",
    "        recommendations['similarity_score'] = scores[0]\n",
    "        \n",
    "        # Filter out articles from history\n",
    "        recommendations = recommendations[~recommendations['news_id'].isin(article_ids)]\n",
    "        recommendations = recommendations.head(n_recommendations)\n",
    "        \n",
    "        return recommendations.reset_index(drop=True)\n",
    "\n",
    "# Example usage\n",
    "def create_recommender(news_path):\n",
    "    \"\"\"\n",
    "    Create and train a news recommender system.\n",
    "    \n",
    "    Parameters:\n",
    "    news_path (str): Path to the MIND dataset news file\n",
    "    \n",
    "    Returns:\n",
    "    NewsRecommender: Trained recommender system\n",
    "    \"\"\"\n",
    "    # Read MIND dataset news file\n",
    "    news_df = pd.read_csv(news_path, sep='\\t', \n",
    "                         names=['news_id', 'category', 'subcategory', 'title', \n",
    "                               'abstract', 'url', 'title_entities', 'abstract_entities'])\n",
    "    \n",
    "    # Initialize and train recommender\n",
    "    recommender = NewsRecommender()\n",
    "    recommender.fit(news_df)\n",
    "    \n",
    "    return recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36dcc6-0996-46ff-9c0d-0177d4a7cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train recommender\n",
    "recommender = create_recommender(\"path/to/mind/news.tsv\")\n",
    "\n",
    "# Get recommendations for a single article\n",
    "recommendations = recommender.get_recommendations(\"N1234\", n_recommendations=5)\n",
    "\n",
    "# Get recommendations based on reading history\n",
    "history_recommendations = recommender.get_recommendations_from_history(\n",
    "    [\"N1234\", \"N5678\"], n_recommendations=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
